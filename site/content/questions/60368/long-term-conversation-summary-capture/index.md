+++
type = "question"
title = "Long term conversation summary capture"
description = '''I have a need to determine over a 30 day period, every single unique TCP/IP conversation (pair of IP addresses) communicating to or from our ERP system (iSeries DB2). To satisfy the curious and/or head off any &quot;you don&#x27;t actually need or want that&quot; ... this is our primary ERP database and we want to...'''
date = "2017-03-27T14:21:00Z"
lastmod = "2017-03-29T09:55:00Z"
weight = 60368
keywords = [ "longduration", "script", "tshark", "ringbuffer", "wireshark" ]
aliases = [ "/questions/60368" ]
osqa_answers = 2
osqa_accepted = true
+++

<div class="headNormal">

# [Long term conversation summary capture](/questions/60368/long-term-conversation-summary-capture)

</div>

<div id="main-body">

<div id="askform">

<table id="question-table" style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><span id="post-60368-upvote" class="ajax-command post-vote up" rel="nofollow" title="I like this post (click again to cancel)"> </span><div id="post-60368-score" class="post-score" title="current number of votes">0</div><span id="post-60368-downvote" class="ajax-command post-vote down" rel="nofollow" title="I dont like this post (click again to cancel)"> </span> <span id="favorite-mark" class="ajax-command favorite-mark" rel="nofollow" title="mark/unmark this question as favorite (click again to cancel)"> </span><div id="favorite-count" class="favorite-count"></div></div></td><td><div id="item-right"><div class="question-body"><p>I have a need to determine over a 30 day period, every single unique TCP/IP conversation (pair of IP addresses) communicating to or from our ERP system (iSeries DB2). To satisfy the curious and/or head off any "you don't actually need or want that" ... this is our primary ERP database and we want to migrate it to SQL, but we are not positive we know of every single external system that integrates directly to the database so we need a way to prove this out. A packet capture is the most right way to be positive IMO.</p><p>I already have a monitor session configured on our core switches sending a copy of all traffic hitting the interface of the iSeries (10.0.0.4) to a 3rd party Windows computer and can see the traffic in Wireshark exactly as I want. I am currently doing a ring capture with a simple filter (host 10.0.0.4) so that it's only direct traffic, no broadcasts. After a few minutes if I stop the capture and run a summary conversation report it is exactly what I want to see.</p><p>The trick is, how can I effectively do this over a long period of time (30 days)? After even 20 minutes it's over 6 GB of capture files so that is not going to be sustainable to just capture for 30 days and then analyze the terabytes of data. I really don't need the full capture at all, my only requirement is to be able to know for 100% certain after 30 days I've recorded every unique IP address that talked with 10.0.0.4. While it would be cool to also know the "what" of the conversation, it's not a requirement.</p><p>Is there a way with tshark or something else to capture only this summary data to disk and not full packets? I'm open to any kind of solution that could run on Windows. I can't do anything directly on the iSeries and there doesn't appear to be a way for it to report that anyway. So I'm limited in what I can see from network traffic on the SPAN port in Windows.</p><p>My current thought train is heading down writing some type of script to execute several times a day against every single file in the ring buffer and concatenate to an ever growing text file:</p><pre><code>tshark -r &quot;filename.pcap&quot; -q -z conv,ip &gt;&gt; giant_summary_file.txt</code></pre><p>I'll get loads of duplicate entries and have to do a lot of text processing later on at the end to remove duplicates and header rows so I don't feel like this is an awesome solution. It also takes around 30 to 45 seconds to run that command against a single 1 GB ring buffer .pcap so I'm worried about the scale if I had 100+ files at a time to check.</p><p>The whole thing just feels so wasteful when really what would be ideal is something that did this type of process:</p><ul><li>watch every packet in real time</li><li>analyze the source &amp; destination IP of each packet, write it to a table in a DB or XML or something</li><li>let that run for 30 days</li></ul><p>As long as what it writes in the table for each packet would be overwritten every time it's the same source &amp; destination, by the end of 30 days I should only have maybe a couple dozen entries.</p><p>Any thoughts or advice appreciated!</p></div><div id="question-tags" class="tags-container tags"><span class="post-tag tag-link-longduration" rel="tag" title="see questions tagged &#39;longduration&#39;">longduration</span> <span class="post-tag tag-link-script" rel="tag" title="see questions tagged &#39;script&#39;">script</span> <span class="post-tag tag-link-tshark" rel="tag" title="see questions tagged &#39;tshark&#39;">tshark</span> <span class="post-tag tag-link-ringbuffer" rel="tag" title="see questions tagged &#39;ringbuffer&#39;">ringbuffer</span> <span class="post-tag tag-link-wireshark" rel="tag" title="see questions tagged &#39;wireshark&#39;">wireshark</span></div><div id="question-controls" class="post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>asked <strong>27 Mar '17, 14:21</strong></p><img src="https://secure.gravatar.com/avatar/969c31fae32558b17bc95241e936395f?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="JSanders4040&#39;s gravatar image" /><p><span>JSanders4040</span><br />
<span class="score" title="11 reputation points">11</span><span title="1 badges"><span class="badge1">●</span><span class="badgecount">1</span></span><span title="1 badges"><span class="silver">●</span><span class="badgecount">1</span></span><span title="4 badges"><span class="bronze">●</span><span class="badgecount">4</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="JSanders4040 has no accepted answers">0%</span></p></div></div><div id="comments-container-60368" class="comments-container"></div><div id="comment-tools-60368" class="comment-tools"></div><div class="clear"></div><div id="comment-60368-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

------------------------------------------------------------------------

<div class="tabBar">

<span id="sort-top"></span>

<div class="headQuestions">

2 Answers:

</div>

</div>

<span id="60393"></span>

<div id="answer-container-60393" class="answer accepted-answer">

<table style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><span id="post-60393-upvote" class="ajax-command post-vote up" rel="nofollow" title="I like this post (click again to cancel)"> </span><div id="post-60393-score" class="post-score" title="current number of votes">2</div><span id="post-60393-downvote" class="ajax-command post-vote down" rel="nofollow" title="I dont like this post (click again to cancel)"> </span> <span class="accept-answer on" rel="nofollow" title="JSanders4040 has selected this answer as the correct answer"> </span></div></td><td><div class="item-right"><div class="answer-body"><p>Since you are only interested in the source and destination addresses you could run limit the frame size to 64 byte. The trace would also reveal UDP/TCP port numbers in case there are other services involved. To keep the file sizes manageable I would split them into files of 100 MB each.</p><p>This can be configured through the capture options (Menu Capture -&gt; Options).</p><ul><li>On the Input-Tab double click the word "default" in the column snaplen and select your desired frame size.</li><li>On the Output-Tab define a file name and set the appropriate check marks.</li><li>Optional: Disable automatic scroll and disable name resolution.</li></ul><p>If required you can merge the tracefile into one large monster using mergecap and run all types of tshark-foo. Personally, I prefer Jasper's <a href="https://www.tracewrangler.com/">TraceWrangler</a>.</p><p>At risk of being banned for mentioning another solution in a Wireshark forum:</p><p>If you want to keep a low profile on the capture engine, a simple Linux system with tcpdump will do.</p><pre><code>tcpdump -s 64 -C 100 -w ./capture_files/longterm_analysis</code></pre><p>Good hunting!</p></div><div class="answer-controls post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>answered <strong>28 Mar '17, 14:23</strong></p><img src="https://secure.gravatar.com/avatar/3b60e92020a427bb24332efc0b560943?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="packethunter&#39;s gravatar image" /><p><span>packethunter</span><br />
<span class="score" title="2137 reputation points"><span>2.1k</span></span><span title="7 badges"><span class="badge1">●</span><span class="badgecount">7</span></span><span title="15 badges"><span class="silver">●</span><span class="badgecount">15</span></span><span title="48 badges"><span class="bronze">●</span><span class="badgecount">48</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="packethunter has 8 accepted answers">8%</span></p></div></div><div id="comments-container-60393" class="comments-container"><span id="60401"></span><div id="comment-60401" class="comment"><div id="post-60401-score" class="comment-score"></div><div class="comment-text"><p>On Windows you can use dumpcap (part of the Wireshark suite) or windump (part of WinPCap found <a href="https://www.winpcap.org/windump/">here</a>) to run a low overhead capture.</p></div><div id="comment-60401-info" class="comment-info"><span class="comment-age">(29 Mar '17, 04:13)</span> <span class="comment-user userinfo">grahamb ♦</span></div></div><span id="60403"></span><div id="comment-60403" class="comment"><div id="post-60403-score" class="comment-score"></div><div class="comment-text"><p>This is very promising so far, thank you! It looks like it's about 2,000 packets a second of relevant traffic during the day, probably tapers way off at night. But if I'm doing the math on that correctly ... each packet will be 64 bytes, so that's about 11 GB per day which is much more manageable. That doesn't even count any compression or anything that might be done. TraceWrangler looks very interesting as well, thank you for the detailed comment! I'll let this go all day and see how it ends up but so far so good.</p></div><div id="comment-60403-info" class="comment-info"><span class="comment-age">(29 Mar '17, 05:37)</span> <span class="comment-user userinfo">JSanders4040</span></div></div><span id="60414"></span><div id="comment-60414" class="comment"><div id="post-60414-score" class="comment-score"></div><div class="comment-text"><p>This worked out really well so I have accepted your answer! I ended up additionally expanding the capture filter to drop the top 10 talkers which were responsible for well over 95% of all the traffic and are already well known / legit. Now I'm getting a very comfortable and manageable stream of only the oddball stuff which is what this exercise was all about. So this should be perfectly reasonable to let run for 30 days now.</p></div><div id="comment-60414-info" class="comment-info"><span class="comment-age">(29 Mar '17, 09:55)</span> <span class="comment-user userinfo">JSanders4040</span></div></div></div><div id="comment-tools-60393" class="comment-tools"></div><div class="clear"></div><div id="comment-60393-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

</div>

<span id="60369"></span>

<div id="answer-container-60369" class="answer">

<table style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><span id="post-60369-upvote" class="ajax-command post-vote up" rel="nofollow" title="I like this post (click again to cancel)"> </span><div id="post-60369-score" class="post-score" title="current number of votes">2</div><span id="post-60369-downvote" class="ajax-command post-vote down" rel="nofollow" title="I dont like this post (click again to cancel)"> </span></div></td><td><div class="item-right"><div class="answer-body"><p>For this kind of thing, gathering and analyzing NetFlow records would be a much better solution, e.g. using <a href="http://www.ntop.org/">ntop</a>.</p></div><div class="answer-controls post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>answered <strong>27 Mar '17, 14:26</strong></p><img src="https://secure.gravatar.com/avatar/c578ba2967741f25aebd6afef702f432?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="Jasper&#39;s gravatar image" /><p><span>Jasper ♦♦</span><br />
<span class="score" title="23806 reputation points"><span>23.8k</span></span><span title="5 badges"><span class="badge1">●</span><span class="badgecount">5</span></span><span title="51 badges"><span class="silver">●</span><span class="badgecount">51</span></span><span title="284 badges"><span class="bronze">●</span><span class="badgecount">284</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="Jasper has 263 accepted answers">18%</span></p></div></div><div id="comments-container-60369" class="comments-container"></div><div id="comment-tools-60369" class="comment-tools"></div><div class="clear"></div><div id="comment-60369-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

</div>

<div class="paginator-container-left">

</div>

</div>

</div>


+++
type = "question"
title = "Analysing large trace file (~800G)"
description = '''Hi folks, I have a problem that I&#x27;m trying to track down for weeks now. It seems that only a full trace from the beginning of the CIFS session (Kerberos ticket exchange) up to the end will help. This will result in a trace of ~ 800G. Obviously I don&#x27;t feel like getting a machine with 1 TB of RAM. Is...'''
date = "2016-02-06T04:57:00Z"
lastmod = "2016-02-07T05:46:00Z"
weight = 49926
keywords = [ "large", "capture-limits", "big_trace_file" ]
aliases = [ "/questions/49926" ]
osqa_answers = 1
osqa_accepted = false
+++

<div class="headNormal">

# [Analysing large trace file (~800G)](/questions/49926/analysing-large-trace-file-800g)

</div>

<div id="main-body">

<div id="askform">

<table id="question-table" style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><span id="post-49926-upvote" class="ajax-command post-vote up" rel="nofollow" title="I like this post (click again to cancel)"> </span><div id="post-49926-score" class="post-score" title="current number of votes">0</div><span id="post-49926-downvote" class="ajax-command post-vote down" rel="nofollow" title="I dont like this post (click again to cancel)"> </span> <span id="favorite-mark" class="ajax-command favorite-mark" rel="nofollow" title="mark/unmark this question as favorite (click again to cancel)"> </span><div id="favorite-count" class="favorite-count"></div></div></td><td><div id="item-right"><div class="question-body"><p>Hi folks,</p><p>I have a problem that I'm trying to track down for weeks now. It seems that only a full trace from the beginning of the CIFS session (Kerberos ticket exchange) up to the end will help. This will result in a trace of ~ 800G.</p><p>Obviously I don't feel like getting a machine with 1 TB of RAM. Is there any way to make WS decode the stream without loading everything into the memory? The point here is that I can search for the packet where something goes wrong because I have the contents of that packet.</p><p>So what I'd like WS to do is to decode the stream up to the packet that I'm looking for, and then let me look back and forth. I there a way to do this with a reasonable dimensioned machine with say 32 G of RAM?</p><p>Thanks Andre</p></div><div id="question-tags" class="tags-container tags"><span class="post-tag tag-link-large" rel="tag" title="see questions tagged &#39;large&#39;">large</span> <span class="post-tag tag-link-capture-limits" rel="tag" title="see questions tagged &#39;capture-limits&#39;">capture-limits</span> <span class="post-tag tag-link-big_trace_file" rel="tag" title="see questions tagged &#39;big_trace_file&#39;">big_trace_file</span></div><div id="question-controls" class="post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>asked <strong>06 Feb '16, 04:57</strong></p><img src="https://secure.gravatar.com/avatar/1f36c3e151eab3dcc2763ee8672913f6?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="Alphaphi&#39;s gravatar image" /><p><span>Alphaphi</span><br />
<span class="score" title="6 reputation points">6</span><span title="1 badges"><span class="badge1">●</span><span class="badgecount">1</span></span><span title="1 badges"><span class="silver">●</span><span class="badgecount">1</span></span><span title="3 badges"><span class="bronze">●</span><span class="badgecount">3</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="Alphaphi has no accepted answers">0%</span></p></div><div class="post-update-info post-update-info-edited"><p><span> edited <strong>07 Feb '16, 05:38</strong> </span></p><img src="https://secure.gravatar.com/avatar/3b24b339fc62fb46dced6a443d3202ea?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="Christian_R&#39;s gravatar image" /><p><span>Christian_R</span><br />
<span class="score" title="1830 reputation points"><span>1.8k</span></span><span title="2 badges"><span class="badge1">●</span><span class="badgecount">2</span></span><span title="6 badges"><span class="silver">●</span><span class="badgecount">6</span></span><span title="25 badges"><span class="bronze">●</span><span class="badgecount">25</span></span></p></div></div><div id="comments-container-49926" class="comments-container"><span id="49929"></span><div id="comment-49929" class="comment"><div id="post-49929-score" class="comment-score"></div><div class="comment-text"><p>These things come first into my mind when I read your question:<br />
- You can split the trace into smaller pieces<br />
- You can use a tool like tracewrangler <a href="https://www.tracewrangler.com">https://www.tracewrangler.com</a> for this<br />
- You can use tshark - You can use tshark outputs with excel</p></div><div id="comment-49929-info" class="comment-info"><span class="comment-age">(06 Feb '16, 06:18)</span> <span class="comment-user userinfo">Christian_R</span></div></div><span id="49935"></span><div id="comment-49935" class="comment"><div id="post-49935-score" class="comment-score"></div><div class="comment-text"><p>800G is a a LOT - TraceWrangler is probably not able to handle it, at least not yet or unless the workstation is a RAM monster.</p><p>Question is: why do you need to look at the whole stream? Is there anything needs to be decrypted or decoded that requires looking at all packets? And is the 800G one single TCP connection? That would be the largest I ever heard of - what is transferred inside?</p></div><div id="comment-49935-info" class="comment-info"><span class="comment-age">(06 Feb '16, 17:00)</span> <span class="comment-user userinfo">Jasper ♦♦</span></div></div><span id="49939"></span><div id="comment-49939" class="comment"><div id="post-49939-score" class="comment-score"></div><div class="comment-text"><p>Hi Jasper, this is a CIFS-Transfer of ~300-400 GB from one NAS storage to another. So the copy box will read in the files to be transferred from the source, and write out everything to the target, which doubles the volume.</p><p>Now I'm not a WS-specialist. But I know one, and he tells me that it is neccessary to capture the Kerberos ticket exchange at the very beginning of the CIFS stream, and then walk along the whole stream up to where the error occurs (which I suspect to be somewhere in the answers from AD, and I want to prove that). I'm looking for a way how to do this without the need of having a 8-TB-RAM-Box.</p></div><div id="comment-49939-info" class="comment-info"><span class="comment-age">(07 Feb '16, 01:01)</span> <span class="comment-user userinfo">Alphaphi</span></div></div><span id="49941"></span><div id="comment-49941" class="comment"><div id="post-49941-score" class="comment-score"></div><div class="comment-text"><p>About what a data rate do we talk.</p><p>And maybe this question gives you a hint how others deal with this requirements. <a href="https://ask.wireshark.org/questions/47868/looking-on-recommendationsbest-practices-on-ws-deployment-at-large-data-centers">https://ask.wireshark.org/questions/47868/looking-on-recommendationsbest-practices-on-ws-deployment-at-large-data-centers</a></p></div><div id="comment-49941-info" class="comment-info"><span class="comment-age">(07 Feb '16, 01:47)</span> <span class="comment-user userinfo">Christian_R</span></div></div><span id="49942"></span><div id="comment-49942" class="comment"><div id="post-49942-score" class="comment-score"></div><div class="comment-text"><p>Data rate is not too high, the source has only a 1-GBit-pipe, so it's max 2 GBit on the copy box.</p></div><div id="comment-49942-info" class="comment-info"><span class="comment-age">(07 Feb '16, 04:45)</span> <span class="comment-user userinfo">Alphaphi</span></div></div><span id="49945"></span><div id="comment-49945" class="comment not_top_scorer"><div id="post-49945-score" class="comment-score"></div><div class="comment-text"><p>Can you describe the overall environment for the capture? In particular:</p><ul><li><p>will you capture on the copybox itself or on a separate machine?</p></li><li><p>whatever the capturing machine will be, will it have a local disk big enough or will it send the capture file to the NAS over Ethernet as well?</p></li></ul></div><div id="comment-49945-info" class="comment-info"><span class="comment-age">(07 Feb '16, 05:40)</span> <span class="comment-user userinfo">sindy</span></div></div><span id="49946"></span><div id="comment-49946" class="comment not_top_scorer"><div id="post-49946-score" class="comment-score"></div><div class="comment-text"><p>Well from point of view: Traces with more then 300MBit/s bandwith are at the border where Wireshark works reliable without some tuning mechanisms. <a href="https://ask.wireshark.org/questions/523/the-peak-of-network-flow-rate-that-wireshark-can-deal-with">https://ask.wireshark.org/questions/523/the-peak-of-network-flow-rate-that-wireshark-can-deal-with</a><br />
Also you should think about the capabilities of the capture point(SPAN Port, TAP, local machine).</p></div><div id="comment-49946-info" class="comment-info"><span class="comment-age">(07 Feb '16, 05:46)</span> <span class="comment-user userinfo">Christian_R</span></div></div></div><div id="comment-tools-49926" class="comment-tools"><span class="comments-showing"> showing 5 of 7 </span> <a href="#" class="show-all-comments-link">show 2 more comments</a></div><div class="clear"></div><div id="comment-49926-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

------------------------------------------------------------------------

<div class="tabBar">

<span id="sort-top"></span>

<div class="headQuestions">

One Answer:

</div>

</div>

<span id="49931"></span>

<div id="answer-container-49931" class="answer">

<table style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><span id="post-49931-upvote" class="ajax-command post-vote up" rel="nofollow" title="I like this post (click again to cancel)"> </span><div id="post-49931-score" class="post-score" title="current number of votes">0</div><span id="post-49931-downvote" class="ajax-command post-vote down" rel="nofollow" title="I dont like this post (click again to cancel)"> </span></div></td><td><div class="item-right"><div class="answer-body"><p>If you by chance already have the file, I'm afraid you'd have to use tcpdump on a linux machine to split it into several files, because dumpcap cannot read from file and both tshark and Wireshark collect protocol state so they are likely to run out of RAM on such a huge file.</p><p>If you are only getting ready for the capture, the easiest way is to tell dumpcap (which you have to use anyway due to RAM limits) to save the data into files not bigger than X megabytes, so <code>-w your_file_name -b filesize:100000 -b files:10000</code> as parameters to dumpcap will create up to 10000 files of 100 MBytes each. You can then use a batch to let tshark search for the pattern you know in all the files, and then you can merge the file where it finds it and the previous one together so that you could work with enough history before the trigger packet.</p></div><div class="answer-controls post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>answered <strong>06 Feb '16, 07:29</strong></p><img src="https://secure.gravatar.com/avatar/00fc6e2633725bd871ff636f0175eabc?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="sindy&#39;s gravatar image" /><p><span>sindy</span><br />
<span class="score" title="6049 reputation points"><span>6.0k</span></span><span title="4 badges"><span class="badge1">●</span><span class="badgecount">4</span></span><span title="8 badges"><span class="silver">●</span><span class="badgecount">8</span></span><span title="51 badges"><span class="bronze">●</span><span class="badgecount">51</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="sindy has 110 accepted answers">24%</span> </br></br></p></div></div><div id="comments-container-49931" class="comments-container"><span id="49933"></span><div id="comment-49933" class="comment"><div id="post-49933-score" class="comment-score"></div><div class="comment-text"><p>Seems I have missed the key point which is the encryption. You'll have to try, or wait for someone who knows for sure to answer, whether you could capture the initial key exchange in the first file, then merge the first and third file together and see whether the decryption algorithm would be able to re-sync and decrypt the data from the third file despite the gap in them.</p></div><div id="comment-49933-info" class="comment-info"><span class="comment-age">(06 Feb '16, 10:04)</span> <span class="comment-user userinfo">sindy</span></div></div><span id="49940"></span><div id="comment-49940" class="comment"><div id="post-49940-score" class="comment-score"></div><div class="comment-text"><p>It's not an encrypted stream. But as said, my WS guru tells me that it is crucial to process the Kerberos ticket at the very beginning of the session all along to where the error occurs. I must find out if the method you outline will do the trick together with the Kerberos ticket.</p><p>And no, I don't have captured the stream yet. At the moment I try to figure out how to do it best (or least painful). Furthermore, I'll have to capture the stream many times, as the error occurs only once in a while :(</p></div><div id="comment-49940-info" class="comment-info"><span class="comment-age">(07 Feb '16, 01:05)</span> <span class="comment-user userinfo">Alphaphi</span></div></div></div><div id="comment-tools-49931" class="comment-tools"></div><div class="clear"></div><div id="comment-49931-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

</div>

<div class="paginator-container-left">

</div>

</div>

</div>


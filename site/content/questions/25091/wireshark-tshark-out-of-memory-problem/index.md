+++
type = "question"
title = "Wireshark, tshark - Out of memory problem"
description = '''Hi all, I&#x27;m using wireshark and tshark to display data. I search on Internet and know that if we run wireshark day after day without stopping, it could cause two problem:  Temp Data written to disk: We have a workaround by adding an option to write into 5 files with default size, when the new 6 th f...'''
date = "2013-09-22T19:46:00Z"
lastmod = "2014-06-19T02:51:00Z"
weight = 25091
keywords = [ "out-of-memory" ]
aliases = [ "/questions/25091" ]
osqa_answers = 4
osqa_accepted = true
+++

<div class="headNormal">

# [Wireshark, tshark - Out of memory problem](/questions/25091/wireshark-tshark-out-of-memory-problem)

</div>

<div id="main-body">

<div id="askform">

<table id="question-table" style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><div id="post-25091-score" class="post-score" title="current number of votes">0</div><div id="favorite-count" class="favorite-count"></div></div></td><td><div id="item-right"><div class="question-body"><p>Hi all, I'm using wireshark and tshark to display data. I search on Internet and know that if we run wireshark day after day without stopping, it could cause two problem:</p><ul><li>Temp Data written to disk: We have a workaround by adding an option to write into 5 files with default size, when the new 6 th file generated, it would replace the 1 st file.</li><li>Wireshark use a lot of memory and auto terminate itself when memory is not enough. We cannot use dumpcap, because it does not support our protocol camel message as wireshark. So, is there any way to fix this problem or I have to modify in the code. I don't want to modify the memory allocation in the code because it could cause many other problem so that I cannot control. But if it is the only way, do you have any suggestion or experience to share? Thanks a lot.</li></ul></div><div id="question-tags" class="tags-container tags">out-of-memory</div><div id="question-controls" class="post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>asked <strong>22 Sep '13, 19:46</strong></p><img src="https://secure.gravatar.com/avatar/824a7342f59ff90e6040505b38626416?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="hoangsonk49&#39;s gravatar image" /><p>hoangsonk49<br />
<span class="score" title="81 reputation points">81</span><span title="28 badges"><span class="badge1">●</span><span class="badgecount">28</span></span><span title="29 badges"><span class="silver">●</span><span class="badgecount">29</span></span><span title="33 badges"><span class="bronze">●</span><span class="badgecount">33</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="hoangsonk49 has 2 accepted answers">28%</span></p></div></div><div id="comments-container-25091" class="comments-container"><span id="25092"></span><div id="comment-25092" class="comment"><div id="post-25092-score" class="comment-score"></div><div class="comment-text"><p>P/S: i don't want to save data into file, I just process information in real time, after that we can throw it away, so no need to keep it any more.</p></div><div id="comment-25092-info" class="comment-info"><span class="comment-age">(22 Sep '13, 19:48)</span> hoangsonk49</div></div><span id="25264"></span><div id="comment-25264" class="comment"><div id="post-25264-score" class="comment-score"></div><div class="comment-text"><blockquote><p>because it does not support our protocol camel message as wireshark. So, is there any way to fix this problem or I have to modify in the code.</p></blockquote><p>what are you trying to do exactly? Maybe there is an alternative.</p></div><div id="comment-25264-info" class="comment-info"><span class="comment-age">(26 Sep '13, 02:17)</span> Kurt Knochner ♦</div></div><span id="25265"></span><div id="comment-25265" class="comment"><div id="post-25265-score" class="comment-score"></div><div class="comment-text"><p>I have a camel protocol in which "camel.local" is what I need. When a message comes, wireshark/tshark can dissect to get the value of "camel.local" and send it to server via socket automatically by source code. But the problem is that our system need to run in real time, day by day, no stopping while we are in trouble with out of memory of wireshark/tshark. So, we don't want to display or store anything. After sending the value, everything could be thrown away. That is our goal.</p></div><div id="comment-25265-info" class="comment-info"><span class="comment-age">(26 Sep '13, 02:59)</span> hoangsonk49</div></div></div><div id="comment-tools-25091" class="comment-tools"></div><div class="clear"></div><div id="comment-25091-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

------------------------------------------------------------------------

<div class="tabBar">

<span id="sort-top"></span>

<div class="headQuestions">

4 Answers:

</div>

</div>

<span id="25290"></span>

<div id="answer-container-25290" class="answer accepted-answer">

<table style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><div id="post-25290-score" class="post-score" title="current number of votes">1</div></div></td><td><div class="item-right"><div class="answer-body"><blockquote><p>I have a camel protocol in which "camel.local" is what I need. When a message comes, wireshark/tshark can dissect to get the value of "camel.local" and send it to server via socket automatically by source code.</p></blockquote><p>O.K. here comes a proposed solution, at least I would do it this way ;-) Some ideas have already been mentioned in comments.</p><p><strong>Proposed solution</strong></p><p>Write a "management application" that handles everything. That application does the following steps in an endless loop.</p><ul><li>mkfifo /tmp/dumpcap (needs to be done only once, not within the loop!)</li><li>spawn: <code>tshark -ni /tmp/dumpcap -T fields -e camel.local | send_data</code></li><li>spawn <strong>and</strong> wait for exit: <code>dumpcap -ni eth0 -f "host x.x.x.x and port xyz" -a duration:500 -P -w - &gt; /tmp/dumpcap</code></li><li>After exit of dumpcap, goto 2.</li></ul><p><strong>Here is how it works.</strong></p><ul><li>We create a named pipe (FIFO) on Linux</li><li>We let tshark read from that named pipe, filter the data and pipe STDOUT to an application that sends the output to your backend database. The application <code>send_data</code> needs to be written as well!</li><li>spawn dumpcap and let the management application wait for the exit of its child.</li><li>dumpcap will run for 500 seconds (-a duration) and write the captured data in libpcap format (option -P - IMPORTANT) to the named pipe, from where tshark reads as soon as there is data.</li><li>As soon as dumpcap stops (after 500 seconds), tshark will be terminated as well, as it detects the EOF on the named pipe</li><li>Now you'll have to repeat these steps in a loop</li></ul><p><strong>This solves your problem because</strong></p><ul><li>dumpcap does not use a temp file</li><li>dumpcap and tshark do not run very long, hence no resource problem.</li><li>tshark needs to handle only the traffic of 500 seconds, which should be possible. If not, just reduce the amount of seconds that dumpcap writes data.</li></ul><p><strong>Caveats</strong></p><ul><li>instead of dumpcap, tshark now uses a temp file. However, if you ensure, that there is enough space for 500 seconds of data (or less), this should be no problem. Try to limit the amount of data as much as possible (see capture filter above: host x.x.x.x and port xyz).</li><li>there is a short time gap where you may miss some packets. It's the moment where tshark and dumpcap need to be restarted. However, that's a rather short time interval and if I had to choose between a non existant solution and this one, guess what ;-)). Furthermore, you might be able to work around that little gap, if you start two instances of tshark/dumpcap with an overlapping of a few seconds (start the second instance shortly before the first one terminates), so you won't miss packets. However you will then get duplicate <strong>camel.location</strong> data. You might be able to filter those duplicates in your backend maybe by using the IP ID, as that will be sent identical from both tshark process while they see the same frames.</li></ul><blockquote><p><code>tshark -ni /tmp/dumpcap -T fields -e ip.id -e camel.local | send_data</code></p></blockquote><p><strong>This sounds to good to be true. Does it really work?</strong></p><p>Well, I did not write a management wrapper. I tested it manually and yes it works on Ubuntu 12.04 with tshark 1.10.</p><p><strong>Will it work on Windows?</strong></p><p>I have no idea. Probably yes as there are named pipes on Windows as well. There is no native mkfifo command, but there are other ways to create a named pipe on Windows (google or your local Linux/Windows hero will tell you).</p><p>Have fun!</p><p>Regards<br />
Kurt</p></div><div class="answer-controls post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>answered <strong>26 Sep '13, 11:13</strong></p><img src="https://secure.gravatar.com/avatar/23b7bf5b13bc2c98b2e8aa9869ca5d75?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="Kurt%20Knochner&#39;s gravatar image" /><p>Kurt Knochner ♦<br />
<span class="score" title="24767 reputation points"><span>24.8k</span></span><span title="10 badges"><span class="badge1">●</span><span class="badgecount">10</span></span><span title="39 badges"><span class="silver">●</span><span class="badgecount">39</span></span><span title="237 badges"><span class="bronze">●</span><span class="badgecount">237</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="Kurt Knochner has 344 accepted answers">15%</span> </br></p></div><div class="post-update-info post-update-info-edited"><p>edited 26 Sep '13, 11:35</p></div></div><div id="comments-container-25290" class="comments-container"></div><div id="comment-tools-25290" class="comment-tools"></div><div class="clear"></div><div id="comment-25290-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

</div>

<span id="25094"></span>

<div id="answer-container-25094" class="answer">

<table style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><div id="post-25094-score" class="post-score" title="current number of votes">0</div></div></td><td><div class="item-right"><div class="answer-body"><p>You could still use dumpcap for the actual capture process, and then do a batch script to run tshark/wireshark on the files that are complete to do the analysis you want, with either remembering what file was already processed or by deleting the ones that are complete.</p></div><div class="answer-controls post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>answered <strong>22 Sep '13, 22:42</strong></p><img src="https://secure.gravatar.com/avatar/c578ba2967741f25aebd6afef702f432?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="Jasper&#39;s gravatar image" /><p>Jasper ♦♦<br />
<span class="score" title="23806 reputation points"><span>23.8k</span></span><span title="5 badges"><span class="badge1">●</span><span class="badgecount">5</span></span><span title="51 badges"><span class="silver">●</span><span class="badgecount">51</span></span><span title="284 badges"><span class="bronze">●</span><span class="badgecount">284</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="Jasper has 263 accepted answers">18%</span></p></div></div><div id="comments-container-25094" class="comments-container"><span id="25143"></span><div id="comment-25143" class="comment"><div id="post-25143-score" class="comment-score"></div><div class="comment-text"><p>actually it is quite complicated, and it could affect our performance. I ever think about that, using tshark to extract data, and then I use Java program to read a text file, but it caused some problems because our system working in real with high performance. Anw, thanks for your suggestion, I should try it again to see if it works well. Btw, do you think code modification is a good way to eliminate the problem completely?</p></div><div id="comment-25143-info" class="comment-info"><span class="comment-age">(23 Sep '13, 18:19)</span> hoangsonk49</div></div><span id="25150"></span><div id="comment-25150" class="comment"><div id="post-25150-score" class="comment-score"></div><div class="comment-text"><p>While I do not know exactly how much work it will actually be, my guess is that code modification is a huge task that will most likely require a lot of work and coordination with the other developers. So I'm not sure if it is possible in a short time frame to solve your current problem with that.</p></div><div id="comment-25150-info" class="comment-info"><span class="comment-age">(23 Sep '13, 22:34)</span> Jasper ♦♦</div></div><span id="25268"></span><div id="comment-25268" class="comment"><div id="post-25268-score" class="comment-score"></div><div class="comment-text"><p>@Jasper: I have some questions: if we use dumpcap, can it solve the problem of memory? Dumpcap does not increase the memory, does it? Dumpcap just save the information into pcap file and not store anything else so that it could run in live network, is it right?@Jasper:</p></div><div id="comment-25268-info" class="comment-info"><span class="comment-age">(26 Sep '13, 03:37)</span> hoangsonk49</div></div><span id="25269"></span><div id="comment-25269" class="comment"><div id="post-25269-score" class="comment-score"></div><div class="comment-text"><p>Yes, correct. I did a test once and wrote 34GByte into a single file without any memory problems.</p></div><div id="comment-25269-info" class="comment-info"><span class="comment-age">(26 Sep '13, 03:39)</span> Jasper ♦♦</div></div></div><div id="comment-tools-25094" class="comment-tools"></div><div class="clear"></div><div id="comment-25094-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

</div>

<span id="25116"></span>

<div id="answer-container-25116" class="answer">

<table style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><div id="post-25116-score" class="post-score" title="current number of votes">0</div></div></td><td><div class="item-right"><div class="answer-body"><p>What version are you using? If you are rotating files then the memory usage problem "should" not be a problem: each time Wireshark goes to a new file the memory used from the last one should be freed. If you're not using the latest release (1.10.2) you might want to upgrade.</p><p>If you're already on 1.10.2 you might want to try a buildbot build--a fair amount of work has gone into fixing memory leaks (although I thought most of them were not run time leaks).</p></div><div class="answer-controls post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>answered <strong>23 Sep '13, 06:59</strong></p><img src="https://secure.gravatar.com/avatar/e0564001bb7deb960d5d9d9c1e0ba074?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="JeffMorriss&#39;s gravatar image" /><p>JeffMorriss ♦<br />
<span class="score" title="6219 reputation points"><span>6.2k</span></span><span title="5 badges"><span class="silver">●</span><span class="badgecount">5</span></span><span title="72 badges"><span class="bronze">●</span><span class="badgecount">72</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="JeffMorriss has 103 accepted answers">27%</span></p></div></div><div id="comments-container-25116" class="comments-container"><span id="25119"></span><div id="comment-25119" class="comment"><div id="post-25119-score" class="comment-score"></div><div class="comment-text"><p>Ary you sure memory is released at file rotation, I thought we retaned state to be able to reassemble packets in two different files for instance.</p></div><div id="comment-25119-info" class="comment-info"><span class="comment-age">(23 Sep '13, 08:44)</span> Anders ♦</div></div><span id="25124"></span><div id="comment-25124" class="comment"><div id="post-25124-score" class="comment-score"></div><div class="comment-text"><p>Oh boy, maybe I'm completely losing my mind... I was pretty sure we did NOT do that (and that we released memory each time we closed a file). I don't know for sure...</p></div><div id="comment-25124-info" class="comment-info"><span class="comment-age">(23 Sep '13, 12:27)</span> JeffMorriss ♦</div></div><span id="25144"></span><div id="comment-25144" class="comment"><div id="post-25144-score" class="comment-score"></div><div class="comment-text"><p>As I know, file rotation just avoid the problem of disk space but it cannot solve the problem of RAM, please correct me if i was wrong. By the way, I'm using the latest version of wireshark.</p></div><div id="comment-25144-info" class="comment-info"><span class="comment-age">(23 Sep '13, 18:24)</span> hoangsonk49</div></div><span id="25256"></span><div id="comment-25256" class="comment"><div id="post-25256-score" class="comment-score"></div><div class="comment-text"><p>is it possible to add all information to proto tree with NULL value so that nothing stored in proto tree? I don't need to display, so do you think by doing this, the problem of memory could be solved ?</p></div><div id="comment-25256-info" class="comment-info"><span class="comment-age">(25 Sep '13, 18:55)</span> hoangsonk49</div></div><span id="25261"></span><div id="comment-25261" class="comment"><div id="post-25261-score" class="comment-score">1</div><div class="comment-text"><p>Nope. Dissectors also save lots of stuff in conversation tables and defragmentation tables.</p><p>It's a major undertaking to resolve this, hopefully the memory allocator changes currently underway might help.</p><p>If it was easy to do it would have been done already.</p></div><div id="comment-25261-info" class="comment-info"><span class="comment-age">(26 Sep '13, 00:32)</span> grahamb ♦</div></div><span id="25263"></span><div id="comment-25263" class="comment not_top_scorer"><div id="post-25263-score" class="comment-score"></div><div class="comment-text"><p>You broke my heart, grahamb, but thanks for your information :-). Hope that the memory allocator can help</p></div><div id="comment-25263-info" class="comment-info"><span class="comment-age">(26 Sep '13, 00:52)</span> hoangsonk49</div></div></div><div id="comment-tools-25116" class="comment-tools"><span class="comments-showing"> showing 5 of 6 </span> <a href="#" class="show-all-comments-link">show 1 more comments</a></div><div class="clear"></div><div id="comment-25116-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

</div>

<span id="33952"></span>

<div id="answer-container-33952" class="answer answered-by-owner">

<table style="width:100%;"><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><tbody><tr class="odd"><td style="width: 30px; vertical-align: top"><div class="vote-buttons"><div id="post-33952-score" class="post-score" title="current number of votes">0</div></div></td><td><div class="item-right"><div class="answer-body"><p>Hi all, After ~9 months since the last comment, I have some experience to share. With near 6 months of running, our service is still working without any problem of memory. Some related information:</p><ul><li>Command: <strong><em>nohup tshark -i 5 -P -w /tmp/Log.pcap -b filesize:655350|split -b 655350000 -a 10 - /tmp/log/call_log- &amp;</em></strong></li><li>I changed the code to make sure that when a <strong><em>Log_xxx.pcap</em></strong> was processed, its name would be changed into <strong><em>Log_xxx.pcap.bak</em></strong> and <strong><em>call_log</em></strong> become <strong><em>call_log_xxx.bak</em></strong> (in order to remove by cronjob)</li><li>Each Log.pcap reaches the limited size (655350) in about 12 minutes. Service is running in real-time.</li><li>Memory of server: 8 GB</li><li>OS: CentOS 5.8</li><li>I use Top to check memory everyday: never greater than 15%</li><li>A cronjob to remove <strong><em>*.bak</em></strong> every 5 days.</li></ul><p>Before running this service, I'm afraid of the problem of memory, but thank God, we are still alive. The service has not been stopped during 6 months, and still working. In theory, it should get the problem but until now, I'm a lucky guy. Maybe,it would get trouble in the future but 6 months of perfect running is a good result. So, sometime, practice is quite different from theory. I share this information to encourage anyone who is afraid of the problem of memory (just like me before:-)). Just try, all theory is grey, but, the glad golden tree of life is green :-)</p></div><div class="answer-controls post-controls"></div><div class="post-update-info-container"><div class="post-update-info post-update-info-user"><p>answered <strong>19 Jun '14, 02:51</strong></p><img src="https://secure.gravatar.com/avatar/824a7342f59ff90e6040505b38626416?s=32&amp;d=identicon&amp;r=g" class="gravatar" width="32" height="32" alt="hoangsonk49&#39;s gravatar image" /><p>hoangsonk49<br />
<span class="score" title="81 reputation points">81</span><span title="28 badges"><span class="badge1">●</span><span class="badgecount">28</span></span><span title="29 badges"><span class="silver">●</span><span class="badgecount">29</span></span><span title="33 badges"><span class="bronze">●</span><span class="badgecount">33</span></span><br />
<span class="accept_rate" title="Rate of the user&#39;s accepted answers">accept rate:</span> <span title="hoangsonk49 has 2 accepted answers">28%</span></p></div></div><div id="comments-container-33952" class="comments-container"><span id="33959"></span><div id="comment-33959" class="comment"><div id="post-33959-score" class="comment-score"></div><div class="comment-text"><p>So, you are saying that <strong>tshark is running for 6 months</strong>, without restarting it a single time <strong>and</strong> you are <strong>not</strong> running into the out of memory problem?</p><blockquote><p>Just try, all theory is grey, but, the glad golden tree of life is green :-)</p></blockquote><p>Why 'theory'? Wasn't it you who reported a out of memory problem? ;-))</p></div><div id="comment-33959-info" class="comment-info"><span class="comment-age">(19 Jun '14, 10:10)</span> Kurt Knochner ♦</div></div><span id="33973"></span><div id="comment-33973" class="comment"><div id="post-33973-score" class="comment-score"></div><div class="comment-text"><blockquote><p>So, you are saying that tshark is running for 6 months, without restarting it a single time and you are not running into the out of memory problem?</p></blockquote><p>Yes, I have not met any trouble of memory. It is running without any crash.</p><blockquote><p>Why 'theory'? Wasn't it you who reported a out of memory problem? ;-))</p></blockquote><p>I'm not the person who reported a problem of memory but actually before working with tshark, I searched on Internet and saw many warnings about problem of memory. It even has a <a href="http://wiki.wireshark.org/KnownBugs/OutOfMemory">report as a known bug</a>. It means if I run tshark for a long time and big data, soon or late, I would met the problem of memory. I don't have much experience on wireshark, so, it is "theory" to me :-)</p></div><div id="comment-33973-info" class="comment-info"><span class="comment-age">(19 Jun '14, 21:26)</span> hoangsonk49</div></div><span id="34036"></span><div id="comment-34036" class="comment"><div id="post-34036-score" class="comment-score"></div><div class="comment-text"><blockquote><p>It even has a report as a known bug. It means if I run tshark for a long time and big data, soon or late,</p></blockquote><p>yes, and it <strong>will/should</strong> happen, so the question is, why it does not happen in your environment.</p><p>What do you see on the line where tshark is listening (I guess eth0)?</p><p>Is that pre-filtered traffic, or the whole traffic on that link, including IP, UDP, TCP, HTTP, SMTP, etc. (actually all protocols)? If it's the later, you <strong>should</strong> run into a memory problem sooner or later, as almost every dissector creates at least an entry in the conversation hash tables. Some dissectors also add data to a conversation (e.g. HTTP). So, the hash table will keep growing as long as tshark is running. There should be other data structures as well in certain dissectors, which would increase the memory usage.</p><p>At least that's my understanding of the dissection engine. So, if you don't see any increase in memory usage after running tshark for 6 months, my understanding of the dissection engine might be wrong. I've started a new question about this 'issue'.</p><blockquote><p><a href="http://ask.wireshark.org/questions/34035/tshark-memory-usage">http://ask.wireshark.org/questions/34035/tshark-memory-usage</a></p></blockquote><p>You are welcome to add your experience, especially about the following parts:</p><ul><li>do you see an increased memory usage of the tshark process?</li><li>can you ensure, that its the same tshark process running for 6 months (same PID)?</li><li>do you pre-filter the traffic on eth0 (switch port/TAP filtering)?</li></ul></div><div id="comment-34036-info" class="comment-info"><span class="comment-age">(22 Jun '14, 08:27)</span> Kurt Knochner ♦</div></div></div><div id="comment-tools-33952" class="comment-tools"></div><div class="clear"></div><div id="comment-33952-form-container" class="comment-form-container"></div><div class="clear"></div></div></td></tr></tbody></table>

</div>

<div class="paginator-container-left">

</div>

</div>

</div>

